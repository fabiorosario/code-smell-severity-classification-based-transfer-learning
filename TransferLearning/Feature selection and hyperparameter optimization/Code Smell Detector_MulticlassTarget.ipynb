{"cells":[{"cell_type":"markdown","metadata":{"id":"fQJ5CYV9Te0X","jp-MarkdownHeadingCollapsed":true},"source":["# **FEATURE SELECTION**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2s2A1RUeUZIV","executionInfo":{"status":"ok","timestamp":1728328188855,"user_tz":180,"elapsed":27618,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}},"outputId":"70ab203f-6d8a-4300-afba-ac9279cc2ba2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2196,"status":"ok","timestamp":1728328191047,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"3PZsO_TltCtL"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/machine learning/Datasets/merged dataset_FE_LM_GC_DC_class balancer.csv', sep=',', encoding='iso-8859-1')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1728328191048,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"ohNQtMJ6MkF9"},"outputs":[],"source":["\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"gczjMn0YIb6s"},"source":["# **DATA PREPROCESSING**\n"]},{"cell_type":"markdown","metadata":{"id":"a-DfpMtio-sq"},"source":["## **Transforming nominal categorical variables into ordinal categorical variabless**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1728328191048,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"EBkygcheFxbf"},"outputs":[],"source":["df['modifier_type'].replace('abstract', 0.0, inplace=True)\n","df['modifier_type'].replace('final', 1.0, inplace=True)\n","df['modifier_type'].replace('other', 2.0, inplace=True)\n","df['visibility_type'].replace('public', 0.0, inplace=True)\n","df['visibility_type'].replace('private', 1.0, inplace=True)\n","df['visibility_type'].replace('protected', 2.0, inplace=True)\n","df['visibility_type'].replace('package', 3.0, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"_NBxZCLzC8Bl"},"source":["## **Predictor and Target Attributes**"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1728328191048,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"v_IhKvOtDAZY"},"outputs":[],"source":["predictors = df.iloc[:, 8:92].values\n","predictors_chi_original = df.iloc[:, [10,11,13,14,15,17,19,21,22,23,25,30,31,33,34,35,37,40,44,54,60,61,62,63,64]].values"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1728328191049,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"wdXWRjHMBAFo"},"outputs":[],"source":["target = df.iloc[:, 7].values"]},{"cell_type":"markdown","metadata":{"id":"Xw6d4rM0C9ZD"},"source":["\n","## **Data Scaling**"]},{"cell_type":"markdown","metadata":{"id":"XcSAxyqTD4dw"},"source":["Standardization (uses the mean and standard deviation as a reference).\n","\n","Normalization (uses maximum and minimum values as a reference)."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2402,"status":"ok","timestamp":1728328193443,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"eMoVJG5kEJSG"},"outputs":[],"source":["from sklearn.preprocessing import (\n","    Normalizer, StandardScaler\n",")\n","predictors_norm = Normalizer().fit_transform(predictors)\n","predictors_stand = StandardScaler().fit_transform(predictors)\n","\n","from sklearn.feature_selection import SelectKBest, chi2, f_classif"]},{"cell_type":"markdown","metadata":{"id":"bD5YirxM2o6J"},"source":["## **PREDICTORS WITHOUT DATA PREPROCESSING AND WITH CHI-SQUARE**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1728328195145,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"4h-z3mcN34KP","outputId":"5642b6a2-44de-420e-cf1e-eefb1cce9eff"},"outputs":[{"output_type":"stream","name":"stdout","text":["10% of selected features: [14 29 37 38 39 40 55 56 63]\n","15% of selected features: [14 29 30 37 38 39 40 52 53 55 56 62 63]\n","20% of selected features: [14 15 19 27 29 30 37 38 39 40 52 53 55 56 60 62 63]\n","25% of selected features: [14 15 17 19 27 29 30 31 33 36 37 38 39 40 52 53 55 56 60 62 63]\n","30% of selected features: [10 14 15 17 19 25 27 29 30 31 33 36 37 38 39 40 45 46 52 53 55 56 60 62\n"," 63]\n"]}],"source":["X = predictors\n","y = target\n","\n","# Use SelectKBest with the chi-square test\n","selector10 = SelectKBest(chi2, k=9)   # Select the 9 best resources, approximately 10%\n","selector15 = SelectKBest(chi2, k=13)  # Select the 13 best resources, approximately 15%\n","selector20 = SelectKBest(chi2, k=17)  # Select the 17 best resources, approximately 20%\n","selector25 = SelectKBest(chi2, k=21)  # Select the 21 best resources, approximately 25%\n","selector30 = SelectKBest(chi2, k=25)  # Select the 25 best resources, approximately 30%\n","X_10 = selector10.fit_transform(X, y)\n","X_15 = selector15.fit_transform(X, y)\n","X_20 = selector20.fit_transform(X, y)\n","X_25 = selector25.fit_transform(X, y)\n","X_30 = selector30.fit_transform(X, y)\n","\n","start_index_independent_variables = 8\n","\n","selector10_indices = selector10.get_support(indices=True)\n","for j in range(len(selector10_indices)):\n","  selector10_indices[j] = selector10_indices[j]+start_index_independent_variables\n","\n","selector15_indices = selector15.get_support(indices=True)\n","for j in range(len(selector15_indices)):\n","  selector15_indices[j] = selector15_indices[j]+start_index_independent_variables\n","\n","selector20_indices = selector20.get_support(indices=True)\n","for j in range(len(selector20_indices)):\n","  selector20_indices[j] = selector20_indices[j]+start_index_independent_variables\n","\n","selector25_indices = selector25.get_support(indices=True)\n","for j in range(len(selector25_indices)):\n","  selector25_indices[j] = selector25_indices[j]+start_index_independent_variables\n","\n","selector30_indices = selector30.get_support(indices=True)\n","for j in range(len(selector30_indices)):\n","  selector30_indices[j] = selector30_indices[j]+start_index_independent_variables\n","\n","print(\"10% of selected features:\", selector10_indices)\n","print(\"15% of selected features:\", selector15_indices)\n","print(\"20% of selected features:\", selector20_indices)\n","print(\"25% of selected features:\", selector25_indices)\n","print(\"30% of selected features:\", selector30_indices)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"oc0M33U6AFsk","executionInfo":{"status":"ok","timestamp":1728328201143,"user_tz":180,"elapsed":310,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_chi_10 = df.iloc[:, selector10_indices].values\n","predictors_chi_15 = df.iloc[:, selector15_indices].values\n","predictors_chi_20 = df.iloc[:, selector20_indices].values\n","predictors_chi_25 = df.iloc[:, selector25_indices].values\n","predictors_chi_30 = df.iloc[:, selector30_indices].values"]},{"cell_type":"markdown","metadata":{"id":"Mo6AnxCXMfIy"},"source":["## **NORMALIZATION AND CHI-SQUARE**"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1728328204453,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"f4_a6jEPOBL1","outputId":"79ba9abc-c3f6-4987-cfd1-b2a85bdb7f77"},"outputs":[{"output_type":"stream","name":"stdout","text":["10% of selected features: [14 15 30 37 38 40 62 63 64]\n","15% of selected features: [14 15 19 29 30 36 37 38 40 56 62 63 64]\n","20% of selected features: [10 14 15 19 27 29 30 36 37 38 40 41 53 56 62 63 64]\n","25% of selected features: [10 14 15 19 27 29 30 31 36 37 38 40 41 52 53 55 56 60 62 63 64]\n","30% of selected features: [10 14 15 17 19 25 27 29 30 31 33 36 37 38 40 41 46 52 53 55 56 60 62 63\n"," 64]\n"]}],"source":["X = predictors_norm\n","y = target\n","\n","# Use SelectKBest with the chi-square test\n","selector10 = SelectKBest(chi2, k=9)   # Select the 9 best resources, approximately 10%\n","selector15 = SelectKBest(chi2, k=13)  # Select the 13 best resources, approximately 15%\n","selector20 = SelectKBest(chi2, k=17)  # Select the 17 best resources, approximately 20%\n","selector25 = SelectKBest(chi2, k=21)  # Select the 21 best resources, approximately 25%\n","selector30 = SelectKBest(chi2, k=25)  # Select the 25 best resources, approximately 30%\n","X_10 = selector10.fit_transform(X, y)\n","X_15 = selector15.fit_transform(X, y)\n","X_20 = selector20.fit_transform(X, y)\n","X_25 = selector25.fit_transform(X, y)\n","X_30 = selector30.fit_transform(X, y)\n","\n","start_index_independent_variables = 8\n","\n","selector10_indices = selector10.get_support(indices=True)\n","for j in range(len(selector10_indices)):\n","  selector10_indices[j] = selector10_indices[j]+start_index_independent_variables\n","\n","selector15_indices = selector15.get_support(indices=True)\n","for j in range(len(selector15_indices)):\n","  selector15_indices[j] = selector15_indices[j]+start_index_independent_variables\n","\n","selector20_indices = selector20.get_support(indices=True)\n","for j in range(len(selector20_indices)):\n","  selector20_indices[j] = selector20_indices[j]+start_index_independent_variables\n","\n","selector25_indices = selector25.get_support(indices=True)\n","for j in range(len(selector25_indices)):\n","  selector25_indices[j] = selector25_indices[j]+start_index_independent_variables\n","\n","selector30_indices = selector30.get_support(indices=True)\n","for j in range(len(selector30_indices)):\n","  selector30_indices[j] = selector30_indices[j]+start_index_independent_variables\n","\n","print(\"10% of selected features:\", selector10_indices)\n","print(\"15% of selected features:\", selector15_indices)\n","print(\"20% of selected features:\", selector20_indices)\n","print(\"25% of selected features:\", selector25_indices)\n","print(\"30% of selected features:\", selector30_indices)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Ngy_M8gGWJUL","executionInfo":{"status":"ok","timestamp":1728328208401,"user_tz":180,"elapsed":353,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_chi_norm10 = df.iloc[:, selector10_indices].values\n","predictors_chi_norm15 = df.iloc[:, selector15_indices].values\n","predictors_chi_norm20 = df.iloc[:, selector20_indices].values\n","predictors_chi_norm25 = df.iloc[:, selector25_indices].values\n","predictors_chi_norm30 = df.iloc[:, selector30_indices].values"]},{"cell_type":"markdown","metadata":{"id":"GjNL4O1JqC1D"},"source":["## **PREDICTORS WITHOUT DATA PREPROCESSING AND WITH ANOVA F-VALUE (analysis of variance)**"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1728328210511,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"BMo0Dkq7xuq8","outputId":"16bae386-cfb8-4b9f-bb54-257b22110f0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["10% of selected features: [10 11 13 14 15 17 19 21 25]\n","15% of selected features: [10 11 13 14 15 17 19 21 22 25 33 35 40]\n","20% of selected features: [ 8 10 11 13 14 15 17 19 21 22 25 31 33 35 37 40 60]\n","25% of selected features: [ 8 10 11 13 14 15 17 19 21 22 23 24 25 31 33 35 37 40 44 60 84]\n","30% of selected features: [ 8 10 11 13 14 15 17 18 19 21 22 23 24 25 26 31 33 35 37 40 43 44 60 70\n"," 84]\n"]}],"source":["X = predictors\n","y = target\n","\n","# Use SelectKBest with the f_classif test\n","selector10 = SelectKBest(f_classif, k=9)   # Select the 9 best resources, approximately 10%\n","selector15 = SelectKBest(f_classif, k=13)  # Select the 13 best resources, approximately 15%\n","selector20 = SelectKBest(f_classif, k=17)  # Select the 17 best resources, approximately 20%\n","selector25 = SelectKBest(f_classif, k=21)  # Select the 21 best resources, approximately 25%\n","selector30 = SelectKBest(f_classif, k=25)  # Select the 25 best resources, approximately 30%\n","X_10 = selector10.fit_transform(X, y)\n","X_15 = selector15.fit_transform(X, y)\n","X_20 = selector20.fit_transform(X, y)\n","X_25 = selector25.fit_transform(X, y)\n","X_30 = selector30.fit_transform(X, y)\n","\n","start_index_independent_variables = 8\n","\n","selector10_indices = selector10.get_support(indices=True)\n","for j in range(len(selector10_indices)):\n","  selector10_indices[j] = selector10_indices[j]+start_index_independent_variables\n","\n","selector15_indices = selector15.get_support(indices=True)\n","for j in range(len(selector15_indices)):\n","  selector15_indices[j] = selector15_indices[j]+start_index_independent_variables\n","\n","selector20_indices = selector20.get_support(indices=True)\n","for j in range(len(selector20_indices)):\n","  selector20_indices[j] = selector20_indices[j]+start_index_independent_variables\n","\n","selector25_indices = selector25.get_support(indices=True)\n","for j in range(len(selector25_indices)):\n","  selector25_indices[j] = selector25_indices[j]+start_index_independent_variables\n","\n","selector30_indices = selector30.get_support(indices=True)\n","for j in range(len(selector30_indices)):\n","  selector30_indices[j] = selector30_indices[j]+start_index_independent_variables\n","\n","print(\"10% of selected features:\", selector10_indices)\n","print(\"15% of selected features:\", selector15_indices)\n","print(\"20% of selected features:\", selector20_indices)\n","print(\"25% of selected features:\", selector25_indices)\n","print(\"30% of selected features:\", selector30_indices)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pnxuX7RjrBDs","executionInfo":{"status":"ok","timestamp":1728328215214,"user_tz":180,"elapsed":367,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_anova_10 = df.iloc[:, selector10_indices].values\n","predictors_anova_15 = df.iloc[:, selector15_indices].values\n","predictors_anova_20 = df.iloc[:, selector20_indices].values\n","predictors_anova_25 = df.iloc[:, selector25_indices].values\n","predictors_anova_30 = df.iloc[:, selector30_indices].values"]},{"cell_type":"markdown","metadata":{"id":"y_8DU36fwrJW"},"source":["## **NORMALIZATION AND ANOVA F-VALUE**\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1728328216822,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"7iwQXO54xvcF","outputId":"137a24b5-cff5-4ff3-b725-30f07742aa8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["10% of selected features: [11 14 15 17 19 21 22 25 37]\n","15% of selected features: [10 11 13 14 15 17 19 21 22 25 33 37 40]\n","20% of selected features: [10 11 13 14 15 16 17 19 21 22 24 25 33 37 40 62 63]\n","25% of selected features: [ 9 10 11 13 14 15 16 17 19 21 22 23 24 25 33 35 37 40 62 63 89]\n","30% of selected features: [ 9 10 11 13 14 15 16 17 18 19 21 22 23 24 25 26 33 34 35 37 40 54 62 63\n"," 89]\n"]}],"source":["X = predictors_norm\n","y = target\n","\n","# Use SelectKBest with the f_classif test\n","selector10 = SelectKBest(f_classif, k=9)   # Select the 9 best resources, approximately 10%\n","selector15 = SelectKBest(f_classif, k=13)  # Select the 13 best resources, approximately 15%\n","selector20 = SelectKBest(f_classif, k=17)  # Select the 17 best resources, approximately 20%\n","selector25 = SelectKBest(f_classif, k=21)  # Select the 21 best resources, approximately 25%\n","selector30 = SelectKBest(f_classif, k=25)  # Select the 25 best resources, approximately 30%\n","X_10 = selector10.fit_transform(X, y)\n","X_15 = selector15.fit_transform(X, y)\n","X_20 = selector20.fit_transform(X, y)\n","X_25 = selector25.fit_transform(X, y)\n","X_30 = selector30.fit_transform(X, y)\n","\n","start_index_independent_variables = 8\n","\n","selector10_indices = selector10.get_support(indices=True)\n","for j in range(len(selector10_indices)):\n","  selector10_indices[j] = selector10_indices[j]+start_index_independent_variables\n","\n","selector15_indices = selector15.get_support(indices=True)\n","for j in range(len(selector15_indices)):\n","  selector15_indices[j] = selector15_indices[j]+start_index_independent_variables\n","\n","selector20_indices = selector20.get_support(indices=True)\n","for j in range(len(selector20_indices)):\n","  selector20_indices[j] = selector20_indices[j]+start_index_independent_variables\n","\n","selector25_indices = selector25.get_support(indices=True)\n","for j in range(len(selector25_indices)):\n","  selector25_indices[j] = selector25_indices[j]+start_index_independent_variables\n","\n","selector30_indices = selector30.get_support(indices=True)\n","for j in range(len(selector30_indices)):\n","  selector30_indices[j] = selector30_indices[j]+start_index_independent_variables\n","\n","print(\"10% of selected features:\", selector10_indices)\n","print(\"15% of selected features:\", selector15_indices)\n","print(\"20% of selected features:\", selector20_indices)\n","print(\"25% of selected features:\", selector25_indices)\n","print(\"30% of selected features:\", selector30_indices)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"D52Jj9q6sLGz","executionInfo":{"status":"ok","timestamp":1728328218080,"user_tz":180,"elapsed":307,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_anova_norm10 = df.iloc[:, selector10_indices].values\n","predictors_anova_norm15 = df.iloc[:, selector15_indices].values\n","predictors_anova_norm20 = df.iloc[:, selector20_indices].values\n","predictors_anova_norm25 = df.iloc[:, selector25_indices].values\n","predictors_anova_norm30 = df.iloc[:, selector30_indices].values"]},{"cell_type":"markdown","metadata":{"id":"hfmWYOrHr_mN"},"source":["## **STANDARDIZATION AND ANOVA F-VALUE**"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1728328219248,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"},"user_tz":180},"id":"pNrdRLS3r-WT","outputId":"5681c6eb-65c8-4f0c-ce0c-d17416601b72"},"outputs":[{"output_type":"stream","name":"stdout","text":["10% of selected features: [10 11 13 14 15 17 19 21 25]\n","15% of selected features: [10 11 13 14 15 17 19 21 22 25 33 35 40]\n","20% of selected features: [ 8 10 11 13 14 15 17 19 21 22 25 31 33 35 37 40 60]\n","25% of selected features: [ 8 10 11 13 14 15 17 19 21 22 23 24 25 31 33 35 37 40 44 60 84]\n","30% of selected features: [ 8 10 11 13 14 15 17 18 19 21 22 23 24 25 26 31 33 35 37 40 43 44 60 70\n"," 84]\n"]}],"source":["X = predictors_stand\n","y = target\n","\n","# Use SelectKBest with the f_classif test\n","selector10 = SelectKBest(f_classif, k=9)   # Select the 9 best resources, approximately 10%\n","selector15 = SelectKBest(f_classif, k=13)  # Select the 13 best resources, approximately 15%\n","selector20 = SelectKBest(f_classif, k=17)  # Select the 17 best resources, approximately 20%\n","selector25 = SelectKBest(f_classif, k=21)  # Select the 21 best resources, approximately 25%\n","selector30 = SelectKBest(f_classif, k=25)  # Select the 25 best resources, approximately 30%\n","X_10 = selector10.fit_transform(X, y)\n","X_15 = selector15.fit_transform(X, y)\n","X_20 = selector20.fit_transform(X, y)\n","X_25 = selector25.fit_transform(X, y)\n","X_30 = selector30.fit_transform(X, y)\n","\n","start_index_independent_variables = 8\n","\n","selector10_indices = selector10.get_support(indices=True)\n","for j in range(len(selector10_indices)):\n","  selector10_indices[j] = selector10_indices[j]+start_index_independent_variables\n","\n","selector15_indices = selector15.get_support(indices=True)\n","for j in range(len(selector15_indices)):\n","  selector15_indices[j] = selector15_indices[j]+start_index_independent_variables\n","\n","selector20_indices = selector20.get_support(indices=True)\n","for j in range(len(selector20_indices)):\n","  selector20_indices[j] = selector20_indices[j]+start_index_independent_variables\n","\n","selector25_indices = selector25.get_support(indices=True)\n","for j in range(len(selector25_indices)):\n","  selector25_indices[j] = selector25_indices[j]+start_index_independent_variables\n","\n","selector30_indices = selector30.get_support(indices=True)\n","for j in range(len(selector30_indices)):\n","  selector30_indices[j] = selector30_indices[j]+start_index_independent_variables\n","\n","print(\"10% of selected features:\", selector10_indices)\n","print(\"15% of selected features:\", selector15_indices)\n","print(\"20% of selected features:\", selector20_indices)\n","print(\"25% of selected features:\", selector25_indices)\n","print(\"30% of selected features:\", selector30_indices)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"iLD86jmusQMj","executionInfo":{"status":"ok","timestamp":1728328220307,"user_tz":180,"elapsed":4,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_anova_stand10 = df.iloc[:, selector10_indices].values\n","predictors_anova_stand15 = df.iloc[:, selector15_indices].values\n","predictors_anova_stand20 = df.iloc[:, selector20_indices].values\n","predictors_anova_stand25 = df.iloc[:, selector25_indices].values\n","predictors_anova_stand30 = df.iloc[:, selector30_indices].values"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"hGyf-noRu8Gc","executionInfo":{"status":"ok","timestamp":1728328221316,"user_tz":180,"elapsed":4,"user":{"displayName":"Fabio Rosario","userId":"00126205617792078853"}}},"outputs":[],"source":["predictors_dict = {'predictors': predictors,\n","                   'predictors_chi_original': predictors_chi_original,\n","                   'predictors_chi_10': predictors_chi_10,\n","                   'predictors_chi_15': predictors_chi_15,\n","                   'predictors_chi_20': predictors_chi_20,\n","                   'predictors_chi_25': predictors_chi_25,\n","                   'predictors_chi_30': predictors_chi_30,\n","                   'predictors_chi_norm10': predictors_chi_norm10,\n","                   'predictors_chi_norm15': predictors_chi_norm15,\n","                   'predictors_chi_norm20': predictors_chi_norm20,\n","                   'predictors_chi_norm25': predictors_chi_norm25,\n","                   'predictors_chi_norm30': predictors_chi_norm30,\n","                   'predictors_anova_10': predictors_anova_10,\n","                   'predictors_anova_15': predictors_anova_15,\n","                   'predictors_anova_20': predictors_anova_20,\n","                   'predictors_anova_25': predictors_anova_25,\n","                   'predictors_anova_30': predictors_anova_30,\n","                   'predictors_anova_norm10': predictors_anova_norm10,\n","                   'predictors_anova_norm15': predictors_anova_norm15,\n","                   'predictors_anova_norm20': predictors_anova_norm20,\n","                   'predictors_anova_norm25': predictors_anova_norm25,\n","                   'predictors_anova_norm30': predictors_anova_norm30,\n","                   'predictors_anova_stand10': predictors_anova_stand10,\n","                   'predictors_anova_stand15': predictors_anova_stand15,\n","                   'predictors_anova_stand20': predictors_anova_stand20,\n","                   'predictors_anova_stand25': predictors_anova_stand25,\n","                   'predictors_anova_stand30': predictors_anova_stand30,\n","                   }"]},{"cell_type":"markdown","metadata":{"id":"VdGvKcYjODGt","jp-MarkdownHeadingCollapsed":true},"source":["# **scikit-optimize**"]},{"cell_type":"markdown","metadata":{"id":"i65VtZ4pcQGP"},"source":["https://scikit-learn.org/stable/modules/tree.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31516,"status":"ok","timestamp":1718623323450,"user":{"displayName":"Fábio do ROSARIO Santos","userId":"07674147573712591550"},"user_tz":180},"id":"ic_svNfGpYkh","outputId":"893ded2f-9ec0-4265-ad9c-fa8bdf2cef9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-optimize in ./meu_projeto_env/lib/python3.10/site-packages (0.10.2)\n","Requirement already satisfied: joblib>=0.11 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (1.4.2)\n","Requirement already satisfied: pyaml>=16.9 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (24.4.0)\n","Requirement already satisfied: numpy>=1.20.3 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (1.26.0)\n","Requirement already satisfied: scipy>=1.1.0 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.0.0 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (1.5.0)\n","Requirement already satisfied: packaging>=21.3 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-optimize) (24.1)\n","Requirement already satisfied: PyYAML in ./meu_projeto_env/lib/python3.10/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in ./meu_projeto_env/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"]}],"source":["!pip install scikit-optimize"]},{"cell_type":"markdown","metadata":{"id":"hw7px-UemoSc","jp-MarkdownHeadingCollapsed":true},"source":["# **RANDOM FOREST**"]},{"cell_type":"markdown","metadata":{"id":"HAUbw5xfcCYy"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"]},{"cell_type":"markdown","metadata":{"id":"qvwxuQvL_hDJ"},"source":["# **Nornalization and Chi-Square**"]},{"cell_type":"markdown","metadata":{"id":"nMX1C2iHobFZ","jp-MarkdownHeadingCollapsed":true},"source":["# **RandomizedSearchCV**"]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the Random Forest model\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'n_estimators': np.arange(50, 1000, 2),\n","    'criterion': ['entropy', 'gini', 'log_loss'],\n","    'max_features': ['sqrt', 'log2', None],\n","    'max_depth': np.arange(1, 20, 1),\n","    'min_samples_split': np.arange(2, 20, 1),\n","    'min_samples_leaf': np.arange(1, 20, 1),\n","    'bootstrap': [True, False]\n","}\n","\n","# Configure RandomizedSearchCV\n","random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, scoring='f1', n_iter=50, cv=5, random_state=42, n_jobs=-1)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    predictors_array = predictors_dict[predictor]\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    random_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = random_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = random_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f}\")"],"metadata":{"id":"rrZo7pDvYTBk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f1zVnixRflUX","jp-MarkdownHeadingCollapsed":true},"source":["# **BayesSearchCV**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDV_OKTKtjzb"},"outputs":[],"source":["from skopt import BayesSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the Random Forest model\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'n_estimators': np.arange(50, 1000, 2),\n","    'criterion': ['entropy', 'gini', 'log_loss'],\n","    'max_features': ['sqrt', 'log2', None],\n","    'max_depth': np.arange(1, 20, 1),\n","    'min_samples_split': np.arange(2, 20, 1),\n","    'min_samples_leaf': np.arange(1, 20, 1),\n","    'bootstrap': [True, False]\n","}\n","\n","# Configure BayesSearchCV\n","bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_dist, scoring='f1', n_iter=50, cv=5, random_state=42, n_jobs=-1)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    predictors_array = predictors_dict[predictor]\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    bayes_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = bayes_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = bayes_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"jH3OocboSGXH","jp-MarkdownHeadingCollapsed":true},"source":["# **XGBOOST**\n","\n","# **The first approach involving Standardization, Chi-square with XGBoost**"]},{"cell_type":"markdown","metadata":{"id":"GuN8w4BxYJDn"},"source":["https://xgboost.readthedocs.io/en/stable/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyWs2KyJUFNb","outputId":"c239dae2-2a8a-486d-e30b-d31f90f1e6bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in ./meu_projeto_env/lib/python3.10/site-packages (2.0.3)\n","Requirement already satisfied: numpy in ./meu_projeto_env/lib/python3.10/site-packages (from xgboost) (1.26.0)\n","Requirement already satisfied: scipy in ./meu_projeto_env/lib/python3.10/site-packages (from xgboost) (1.13.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install xgboost"]},{"cell_type":"markdown","metadata":{"id":"I1JmSyj9wln1","jp-MarkdownHeadingCollapsed":true},"source":["# **RandomizedSearchCV**\n","\n","> Adicionar aspas\n","\n"]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the XGBoost model\n","xg = XGBClassifier(random_state=42, verbosity=0)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'n_estimators': np.arange(50, 1000, 2),\n","    'max_depth': np.arange(1, 20, 1),\n","    'booster' : ['gbtree', 'dart'],\n","    'tree_method' : ['exact', 'approx', 'hist'],\n","    'grow_policy' : ['depthwise', 'lossguide'],\n","    'learning_rate' : np.linspace(0.01, 0.5, 30)\n","}\n","\n","# Configure RandomizedSearchCV\n","random_search = RandomizedSearchCV(estimator=xg, param_distributions=param_dist, scoring='f1', n_iter=50, cv=5, random_state=42, n_jobs=-1)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    predictors_array = predictors_dict[predictor]\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    random_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = random_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = random_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f}\")"],"metadata":{"id":"5Nx5cTZ-YJkL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYzPVdFa4-lp","jp-MarkdownHeadingCollapsed":true},"source":["# **BayesSearchCV**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Q1V3KCQQwu6r"},"outputs":[],"source":["from xgboost import XGBClassifier\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Integer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","import cupy as cp\n","import time\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the XGBoost model\n","xg = XGBClassifier(random_state=42, device='cuda', verbosity=0)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'n_estimators': np.arange(50, 1000, 2),\n","    'max_depth': np.arange(1, 20, 1),\n","    'booster' : ['gbtree', 'dart'],\n","    'tree_method' : ['approx', 'hist'],\n","    'grow_policy' : ['depthwise', 'lossguide'],\n","    'learning_rate' : np.linspace(0.01, 0.5, 30)\n","}\n","\n","# Configure BayesSearchCV\n","bayes_search = BayesSearchCV(estimator=xg, search_spaces=param_dist, scoring='f1', n_iter=50, cv=5, random_state=42, n_jobs=-1)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    start = time.time()\n","\n","    predictors_array = predictors_dict[predictor]\n","    predictors_array = cp.array(predictors_array).get()\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    bayes_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = bayes_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = bayes_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f};{(str(time.time() - start))}\")"]},{"cell_type":"markdown","metadata":{"id":"yKpYGEuWUChU"},"source":["# **CATBOOST**"]},{"cell_type":"markdown","metadata":{"id":"LMqQ_NMTUChV"},"source":["https://catboost.ai/en/docs/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30636,"status":"ok","timestamp":1718465741126,"user":{"displayName":"Fábio do ROSARIO Santos","userId":"07674147573712591550"},"user_tz":180},"id":"Vkt7hfJVUChV","outputId":"29ce3cfa-2979-4a52-980a-b3813567b318"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: catboost in ./meu_projeto_env/lib/python3.10/site-packages (1.2.5)\n","Requirement already satisfied: graphviz in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (3.9.0)\n","Requirement already satisfied: numpy>=1.16.0 in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (1.26.0)\n","Requirement already satisfied: pandas>=0.24 in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (5.22.0)\n","Requirement already satisfied: six in ./meu_projeto_env/lib/python3.10/site-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in ./meu_projeto_env/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in ./meu_projeto_env/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in ./meu_projeto_env/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: contourpy>=1.0.1 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (24.1)\n","Requirement already satisfied: pillow>=8 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in ./meu_projeto_env/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\n","Requirement already satisfied: tenacity>=6.2.0 in ./meu_projeto_env/lib/python3.10/site-packages (from plotly->catboost) (8.4.1)\n"]}],"source":["#Instalação\n","!pip install catboost"]},{"cell_type":"markdown","source":["# **RandomizedSearchCV**"],"metadata":{"id":"7H_eAIxfX528"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBYMqODcUFNg"},"outputs":[],"source":["from catboost import CatBoostClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the CatBoost model\n","catboost = CatBoostClassifier(task_type='CPU', thread_count=-1, random_state = 42, verbose=False)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'iterations': np.arange(50, 1000, 2),\n","    'depth': np.arange(1, 16, 1),\n","    'learning_rate': np.linspace(0.01, 0.5, 30),\n","    'l2_leaf_reg': np.arange(1, 10, 1),\n","    'border_count': np.arange(32, 256, 16),\n","    'feature_border_type' : ['Median', 'Uniform', 'UniformAndQuantiles', 'GreedyLogSum', 'MaxLogSum', 'MinEntropy'],\n","    'leaf_estimation_method' : ['Newton', 'Gradient'],\n","    'auto_class_weights' : ['Balanced', 'SqrtBalanced'],\n","    'grow_policy' : ['SymmetricTree', 'Lossguide', 'Depthwise'],\n","    'bootstrap_type' : ['Bayesian', 'Bernoulli', 'MVS', 'No']\n","}\n","\n","# Configure RandomizedSearchCV\n","random_search = RandomizedSearchCV(estimator=catboost, param_distributions=param_dist, scoring='f1', cv=5, n_iter=50, n_jobs=-1, random_state=42)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    predictors_array = predictors_dict[predictor]\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    random_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = random_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = random_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f}\")"]},{"cell_type":"markdown","source":["# **BayesSearchCV**"],"metadata":{"id":"7J8y2U5RX7sa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sN1cf8TSb6Uo"},"outputs":[],"source":["from catboost import CatBoostClassifier\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Integer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n","\n","# Define the CatBoost model\n","catboost = CatBoostClassifier(task_type='CPU', thread_count=-1, random_state = 42, verbose=False)\n","\n","# Define the hyperparameter grid for the search\n","param_dist = {\n","    'iterations': np.arange(50, 1000, 2),\n","    'depth': np.arange(1, 16, 1),\n","    'learning_rate': np.linspace(0.01, 0.5, 30),\n","    'l2_leaf_reg': np.arange(1, 10, 1),\n","    'border_count': np.arange(32, 256, 16),\n","    'feature_border_type' : ['Median', 'Uniform', 'UniformAndQuantiles', 'GreedyLogSum', 'MaxLogSum', 'MinEntropy'],\n","    'leaf_estimation_method' : ['Newton', 'Gradient'],\n","    'auto_class_weights' : ['Balanced', 'SqrtBalanced'],\n","    'grow_policy' : ['SymmetricTree', 'Lossguide', 'Depthwise'],\n","    'bootstrap_type' : ['Bayesian', 'Bernoulli', 'MVS', 'No']\n","}\n","\n","# Configure BayesSearchCV\n","bayes_search = BayesSearchCV(estimator=catboost, search_spaces=param_dist, scoring='f1', cv=5, n_iter=50, random_state=42)\n","\n","predictors_keys = list(predictors_dict.keys())\n","\n","for predictor in predictors_keys:\n","\n","    predictors_array = predictors_dict[predictor]\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(predictors_array, target, test_size=0.3, random_state=42)\n","\n","    # Adjust the model\n","    bayes_search.fit(X_train, y_train)\n","\n","    # Best hyperparameter combination\n","    best_params = bayes_search.best_params_\n","\n","    # Evaluate the optimized model on the test set\n","    best_estimator = bayes_search.best_estimator_\n","    y_pred_test = best_estimator.predict(X_test)\n","    y_pred_train = best_estimator.predict(X_train)\n","    accuracy_train = accuracy_score(y_train, y_pred_train)\n","    accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","    result = cross_val_score(best_estimator, predictors_array, target, cv = kfold)\n","\n","    print(f\"{predictor};{best_params};{accuracy_train*100:.2f};{accuracy_test*100:.2f};{result.mean()*100:.2f};{result.std()*100:.2f}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}